= Processamento Digital de Imagens =


= Introdução =

Processamento digital de imagens é toda manipulação feita por um sistema computacional que tem como entrada e saída uma imagem. O uso do processamento de imagens vem crescendo muito nos últimos tempos, sendo importante em diversas áreas de estudo e pesquisa. Na área médica, por exemplo, um padrão de armazenamento e transferência de imagens, o DICOM (Digital Imaging and Communications in Medicine), se tornou imprenscindível, facilitando o dia a dia dos médicos. 

Ciente da importância do uso de processamento de imagens e de sua aplicabiliade, tarefas da disciplina de Processamento Digital de Imagens foram realizadas e serão apresentadas no relatório a seguir. Tais tarefas possuem como objetivo fortalecer os conceitos teóricos apresentados em sala de aula, bem como sua aplicação na prática e no desenvolvimento de códigos computacionais. É importante ressaltar que a ferramenta utilizada para o desenvolvimento dos exercícios foi o OpenCV. O OpenCV é uma biblioteca multiplataforma, com suporte para Python, C++, C e outras linguagens de programação, para o desenvolvimento de aplicações na área de visão computacional.

= Desenvolvimento =

Os exercícios foram resolvidos utilizando o OpenCV, ferramenta usada em processamento digital de imagens, como dito anteriormente, e a linguagem de programação, c++. Essa linguagem  foi escolhida por causa dos exemplos, tomados como referência, estarem em c++ e a uma vasta documentação encontrada facilmente na internet. Logo a seguir a descrição do problema, comentários a respeito do programa e os códigos de cada tarefa resolvida serão apresentados.  

== Tarefa 1 ==

Tem como objetivo aprender a manipular pixels de uma imagem. O programa pede que o usuário digite dois pontos P1 e P2 nos limites da imagem e apresente a imagem com o respectivo retângulo em negativo. O usuário digita as coordenadas do primeiro ponto para obter a origem do retângulo. O segundo ponto, no entanto, corresponde aos lados do retângulo, partindo da origem estabelecida anteriormente. As restrições dos limites da imagem são comentadas no código. A imagem do Biel foi retirada do http://agostinhobritojr.github.io/tutoriais/pdi/[site do professor] e pode ser vista com o efeito negativo do programa.


Figura 1 - Manipulação de pixels

image:Imagens/Q1.png[Figura 1]


[source, c++]
---------------------
#include <iostream>
//#include <cv.h>
#include <opencv/highgui.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

using namespace cv;
using namespace std;

int main(int, char**){

    Mat image = imread("biel.png", CV_LOAD_IMAGE_GRAYSCALE);
    cv::Size medida;
    medida = image.size();
    //i nao pode ser maior que largura
    //j nao pode ser maior que a altura
    //O primeiro par de coordenadas deve ser a origem do retângulo
    //O segundo par deve ser os lados do retângulo
    int x1, y1, x2, y2;


    std::cout << "Digite P1 (origem do seu retângulo) entre 0 e "<< medida.height<< std::endl;
    std::cin >> x1 >> y1;
    if (((x1 < 0) || (x1 > medida.height)) || ((y1 < 0) || (y1 > medida.width))){
      std::cout << "Ponto inválido\n" << std::endl;
      exit(0);
    }
    // Optei pra que o usuário inserisse apenas valores pro segundo ponto maiores
    // que os valores do primeiro
    std::cout << "Digite x2 maior que "<< x1 << " e menor que " << medida.width << std::endl;
    std::cin >> x2;
    std::cout << "Digite y2 maior que "<< y1 << " e menor que " << medida.width << std::endl;
    std::cin >> y2;
    if ( ((x2 <= x1) || (x2 > medida.height)) || ((y2 <= y1) || (y2 > medida.width))) {
      std::cout << "Ponto inválido\n" << std::endl;
      exit(0);
    }

    for(int i= x1; i < x2;i++){
      for(int j=y1; j< y2;j++){

          image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);

    }
  }
     imshow("Imagem", image);

     waitKey();
     return 0;
}

---------------------
== Tarefa 2 ==
Seguindo a mesma linha da questão anterior, manipulação de pixels. O programa abaixo pega uma imagem, divide-a em quatro pedaços e os imprime dentro em posições diferentes, http://agostinhobritojr.github.io/tutoriais/pdi/[como pode ser visto na figura 2]. A imagem aparenta ser uma espécie de quebra-cabeça. Para a realização dessa tarefa, a classe Rect do OpenCV foi utilizada. Essa tem como função descrever retângulos em 2D e pode ser descrita pela determinação dos seus parâmetros: os dois primeiros, que correspondem ao ponto que determina a origem do retângulo e os outros dois, a largura e a altura. Por exemplo, o primeiro quadrante da imagem fica na origem 0, 0, um dos seus lados tem largura/2 e o outro altura/2. 

Figura 2 - Imagem quebra-cabeça

image:Imagens/Q2.png[Figura 2]

[source, c++]
--------------------
#include <iostream>
//#include <cv.h>
#include <opencv/highgui.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

using namespace cv;

int main(int argc, char const *argv[]) {

  Mat imagem = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  Mat imagem1, imagem2, imagem3, imagem4;

  int largura = imagem.rows;
  int altura = imagem.cols;
  Mat nova_imagem(0,0, altura, largura);
  nova_imagem = imagem;


  imagem1 = imagem(Rect(altura/2, largura/2, altura/2, largura/2));
  imagem2 = imagem(Rect(altura/2, 0, altura/2, largura/2));
  imagem3 = imagem(Rect(0, largura/2, altura/2, largura/2));
  imagem4 = imagem(Rect(0, 0, altura/2, largura/2));



  imagem1.copyTo(nova_imagem(Rect(0, 0, altura/2, largura/2)));
  imagem2.copyTo(nova_imagem(Rect(altura/2, largura/2, altura/2, largura/2)));
  imagem3.copyTo(nova_imagem(Rect(altura/2, 0, altura/2, largura/2)));
  imagem4.copyTo(nova_imagem(Rect(0, largura/2, altura/2, largura/2)));

  
   imshow("Imagem", nova_imagem);
   waitKey();

  return 0;
}
--------------------
== Tarefa 3 ==

Esta tarefa corresponde ao exercício 5.1 do http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[site da disciplina de Processamento Digital de Imagens], que tem como finalidade equalizar as imagens capturadas antes de exibi-las. O resultado pode ser visto e comparado com a imagem original, figura 3. Observa-se então, que a operação de equalização corresponde a aumentar o contraste da imagem. 

Para realizar a operação pedida, é válido calcular o histograma da imagem dentro de uma faixa pré estabelicida, obter o histograma acumulado, normalizá-lo e em seguida aplicar a transformação. De sorte que o OpenCV fornece uma função que faz todo esse trabalho: equalizeHist(). Ela, como o própio nome já diz, realiza a equalização do histograma, recebendo como parâmetros a componente de um vetor de matrizes e uma matriz, onde será armazenada uma determinada componente de cor. Além dessa função, foram utilizadas as funções push_back() e merge(). A primeira adiciona uma matriz como componente de um vetor de matrizes e a segunda combina várias matrizes do vetor em uma única. As demais funções podem ser visualizadas e compreendidas no http://agostinhobritojr.github.io/tutoriais/pdi/[site do professor], na sessão 5.  


Figura 3 - Equalização de histograma

image:Imagens/equilize.png

[source, c++]
--------------------
#include "opencv2/opencv.hpp"
#include <iostream>

using namespace std;
using namespace cv;

int main(int, char**){

    VideoCapture cap(0); // abre camera


    if(!cap.isOpened())  // checagem
        return -1;

    namedWindow("Imagem de vídeo", 1);

    for(;;)
    {
        Mat frame;

        //Vector de matrizes para guardar as cores R, G e B
        vector<Mat> planes;
        //Pega novo frame
        cap >> frame;
        //Pega as matrizes R, G e B dos frames e guarda no vetor de matrizes, faz o inverso do merge, que será descrito abaixo.
        //Pega matriz, frame, e retira as componentes R, G e B e guarda no vetor de matrizes.
        split (frame, planes);
        //Declara três matrizes (RGB)
        Mat B,G,R;

        //Equaliza as componeste separadamente
        equalizeHist( planes[0], B );
        equalizeHist( planes[1], G );
        equalizeHist( planes[2], R );

        //Vector de matrizes
        vector<Mat> combined;
        //Adiona a matriz B equalizada ao vetor de matrizes combined
        combined.push_back(B);
        //Adiona a matriz G equalizada ao vetor de matrizes combined
        combined.push_back(G);
        //Adiona a matriz R equalizada ao vetor de matrizes combined
        combined.push_back(R);

        //Cria matriz para mostrar resultado equalizado
        Mat result;

        //combina as várias matrizes do vetor de matrizes combined (R,G e B) numa única matriz, result.
        merge(combined,result);
        //Mostra frame
        imshow("Video equalizado", result);
        imshow("Video", frame);

        if(waitKey(30) >= 0) break;
    }

      return 0;
}
--------------------

== Tarefa 4 ==

Corresponde a 5.2, motiondetector

[source, c++]
--------------------
#include <iostream>
#include <stdlib.h>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;

  VideoCapture cap;
  vector<Mat> planes;
  Mat histR, histR_1;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  cap.open(0);

  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }


  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  //Não precisa de mais um cálculo

  while(1){
    cap >> image;
    split (image, planes);
    calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);

    calcHist(&planes[0], 1, 0, Mat(), histR_1, 1,
              &nbins, &histrange,
              uniform, acummulate);

    cout << histR <<"--"<< histR_1 <<endl;

    // normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    // normalize(histR_1, histR_1, 0, histImgR.rows, NORM_MINMAX, -1, Mat());

    //histImgR.setTo(Scalar(0));
    //
    // for(int i=0; i<nbins; i++){
    //   line(histImgR, Point(i, histh),
    //        Point(i, cvRound(histR.at<float>(i))),
    //        Scalar(0, 0, 255), 1, 8, 0);
    //
    // }
    //histImgR.copyTo(image(Rect(0, 0,nbins, histh)));
    //Repetindo o mesmo cálculo do histograma da componente de cor num instante depois


    // imshow("image", image);

     //if(waitKey(30) >= 0) break;
   }
   
  return 0;
}
--------------------

== Tarefa 5 ==
A tarefa 5 Corresponde ao exercício 6.2 em, http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[github do professor]. Essa tarefa tem por finalidade apresentar 5 tipos de filtros já implementados no programa base do link mostrado. A saber, filtro da média, detector de bordas verticais e horizontais, gaussiano e laplaciano. Além de apresentá-los, pede-se para gerar um efeito do filtro do laplaciano do gaussiano.

O resultado pode ser visualizado na imagem a seguir. Comparando-o com o laplaciano e o gaussiano, pode-se chegar a conclusão que o filtro laplaciano do gaussiano tem as característacas dos dois, ou seja, uma pequena atenuação proviniente do gaussiano e um acentuado realce em regiões de descontinuidade do laplaciano. 

Em relação a programação, ao código base foi acrescentado um "case" onde o laplaciano do gaussiano é realizado. Para um maior entendimento, sugere que se vá ao endereço: link. Lá se encontra uma descrição melhor de todo o código. 


Figura 3 - Lapaciano do Gaussiano

image:Imagens/LoG.png[Laplaciano do Gaussiano] 


[source, c++]
--------------------
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
    "m - media\n"
    "g - gauss\n"
    "v - vertical\n"
	"h - horizontal\n"
    "l - laplaciano\n"
      "t - laplaciano-gaussiano\n"
	"esc - sair\n";
}

int main(int argvc, char** argv){
  VideoCapture video;
  //Maskaras
  float media[] = {1,1,1,
				   1,1,1,
				   1,1,1};
  float gauss[] = {1,2,1,
				   2,4,2,
				   1,2,1};
  float horizontal[]={-1,0,1,
					  -2,0,2,
					  -1,0,1};
  float vertical[]={-1,-2,-1,
					0,0,0,
					1,2,1};
  float laplacian[]={0,-1,0,
					 -1,4,-1,
					 0,-1,0};
  //Declaração das variáveis do tipo Mat
  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
  // double width, height, min, max;
  int absolut;
  char key;

  video.open(0);
  if(!video.isOpened())
    return -1;


  namedWindow("filtroespacial",1);
  //Inicialmente a máscara vai receber a máscara da média
  mask = Mat(3, 3, CV_32F, media);
  //Retirei a ganho que se tinha pra media
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1); //Pra dar o ganho de 1/9 na máscara da mádia
  swap(mask, mask1);
  absolut=1; // calcs abs of the image

  menu();
  for(;;){
    video >> cap;
    //Converte cap em cinza e manda pra frame
    cvtColor(cap, frame, COLOR_BGR2GRAY);
    flip(frame, frame, 1);
    //Mostra imagens originais
    imshow("original", frame);
    //Frame é convertido pra ponto flutuante e jogado em frame32f
    //Filtra e joga em frameFiltered. Usa mask como maskara. A média inicialmente
    frame.convertTo(frame32f, CV_32F);
    filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);

    if(absolut){
      frameFiltered=abs(frameFiltered);
    }
    //Converte frameFiltered pra poder exibir
    frameFiltered.convertTo(result, CV_8U);
    imshow("filtroespacial", result);

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
	  menu();
      absolut=!absolut;
      break;
    case 'm':
	  menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'g':
	  menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'h':
	  menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      break;
    case 'v':
	  menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      break;
    case 'l':
	  menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);

      break;
    case 't':
    menu();
        // mask recebe os coeficientes da matriz do laplaciano
        // Não precisa converter pra cv_32f, pois a imagem (frame) já entra convertida
        // depois disso se usa a função filter2D() para realizar o filtro do laplaciano. O código segue ainda dentro do case, onde agora
        // mask vai receber a máscara pro gaussiano, recebe um ganho através da função scaleAdd(), sai do break e volta pro começo do loop infinito
        // onde deve ser filtrada por filter2D()
        mask = Mat(3, 3, CV_32F, laplacian);
        filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);



        mask = Mat(3, 3, CV_32F, gauss);
        scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
        swap(mask, mask1);
        
        std::cout << "Laplaciano-gaussiano" << std::endl;
        break;

    default:
      break;
    }
  }
  return 0;
}

--------------------
= Conclusão =

Tendo em mente a importância de PDI, blá, blá


= Bibliografia =
