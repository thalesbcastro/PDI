= Processamento Digital de Imagens =

Thales Castro <thalescast@gmail.com>

Tiago Batista <ekyidag@gmail.com>


= Introdução =

Processamento digital de imagens é toda manipulação feita por um sistema computacional que tem como entrada e saída uma imagem. O uso do processamento de imagens vem crescendo muito nos últimos tempos, sendo importante em diversas áreas de estudo e pesquisa. Na área médica, por exemplo, um padrão de armazenamento e transferência de imagens, o DICOM (Digital Imaging and Communications in Medicine), se tornou imprenscindível, facilitando o dia a dia dos médicos. 

Ciente da importância do uso de processamento de imagens e de sua aplicabiliade, tarefas da disciplina de Processamento Digital de Imagens foram realizadas e serão apresentadas no relatório a seguir. Tais tarefas possuem como objetivo fortalecer os conceitos teóricos apresentados em sala de aula, bem como sua aplicação na prática e no desenvolvimento de códigos computacionais. É importante ressaltar que a ferramenta utilizada para o desenvolvimento dos exercícios foi o OpenCV. O OpenCV é uma biblioteca multiplataforma, com suporte para Python, C++, C e outras linguagens de programação, para o desenvolvimento de aplicações na área de visão computacional.

= Desenvolvimento =

Os exercícios foram resolvidos utilizando o OpenCV, ferramenta usada em processamento digital de imagens, como dito anteriormente, e a linguagem de programação, c++. Essa linguagem  foi escolhida por causa dos exemplos, tomados como referência, estarem em c++ e a uma vasta documentação encontrada facilmente na internet. Logo a seguir a descrição do problema, comentários a respeito do programa e os códigos de cada tarefa resolvida serão apresentados.  

Obs.: todos os programas que foram aqui colocados, seguiram a ideia dos exemplos do http://agostinhobritojr.github.io/tutoriais/pdi/[site do professor]. O nome de cada programa é o nome sugerido do exercício correspondente e para a compilação foi usado os mesmos comandos. Vale ressaltar que a versão do OpenCV utilizada, foi a de número 3 e que os programas foram editados no https://atom.io/[Atom].

== Tarefa 1 

Tem como objetivo aprender a manipular pixels de uma imagem. O programa pede que o usuário digite dois pontos P1 e P2 nos limites da imagem e apresente a imagem com o respectivo retângulo em negativo. O usuário digita as coordenadas do primeiro ponto para obter a origem do retângulo. O segundo ponto, no entanto, corresponde aos lados do retângulo, partindo da origem estabelecida anteriormente. As restrições dos limites da imagem são comentadas no código. A imagem do Biel foi retirada do http://agostinhobritojr.github.io/tutoriais/pdi/[site do professor] e pode ser vista com o efeito negativo do programa.


Figura 1 - Manipulação de pixels

[.left.thumb]
image:Imagens/Q1.png[Wolpertinger,pdfwidth=50%]

[source, c++]
---------------------
#include <iostream>
//#include <cv.h>
#include <opencv/highgui.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

using namespace cv;
using namespace std;

int main(int, char**){

    Mat image = imread("biel.png", CV_LOAD_IMAGE_GRAYSCALE);
    cv::Size medida;
    medida = image.size();
    //i nao pode ser maior que largura
    //j nao pode ser maior que a altura
    //O primeiro par de coordenadas deve ser a origem do retângulo
    //O segundo par deve ser os lados do retângulo
    int x1, y1, x2, y2;


    std::cout << "Digite P1 (origem do seu retângulo) entre 0 e "<< medida.height<< std::endl;
    std::cin >> x1 >> y1;
    if (((x1 < 0) || (x1 > medida.height)) || ((y1 < 0) || (y1 > medida.width))){
      std::cout << "Ponto inválido\n" << std::endl;
      exit(0);
    }
    // Optei pra que o usuário inserisse apenas valores pro segundo ponto maiores
    // que os valores do primeiro
    std::cout << "Digite x2 maior que "<< x1 << " e menor que " << medida.width << std::endl;
    std::cin >> x2;
    std::cout << "Digite y2 maior que "<< y1 << " e menor que " << medida.width << std::endl;
    std::cin >> y2;
    if ( ((x2 <= x1) || (x2 > medida.height)) || ((y2 <= y1) || (y2 > medida.width))) {
      std::cout << "Ponto inválido\n" << std::endl;
      exit(0);
    }

    for(int i= x1; i < x2;i++){
      for(int j=y1; j< y2;j++){

          image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);

    }
  }
     imshow("Imagem", image);

     waitKey();
     return 0;
}

---------------------
== Tarefa 2 ==

Seguindo a mesma linha da questão anterior, manipulação de pixels. O programa abaixo pega uma imagem, divide-a em quatro pedaços e os imprime dentro em posições diferentes, como pode ser visto na figura 2. A imagem aparenta ser uma espécie de quebra-cabeça. Para a realização dessa tarefa, a classe Rect do OpenCV foi utilizada. Essa tem como função descrever retângulos em 2D e pode ser descrita pela determinação dos seus parâmetros: os dois primeiros, que correspondem ao ponto que determina a origem do retângulo e os outros dois, a largura e a altura. Por exemplo, o primeiro quadrante da imagem fica na origem 0, 0, um dos seus lados tem largura/2 e o outro altura/2. 

Figura 2 - Imagem quebra-cabeça

image:Imagens/Q2.png[Figura 2]

[source, c++]
--------------------
#include <iostream>
//#include <cv.h>
#include <opencv/highgui.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

using namespace cv;

int main(int argc, char const *argv[]) {

  Mat imagem = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  Mat imagem1, imagem2, imagem3, imagem4;

  int largura = imagem.rows;
  int altura = imagem.cols;
  Mat nova_imagem(0,0, altura, largura);
  nova_imagem = imagem;


  imagem1 = imagem(Rect(altura/2, largura/2, altura/2, largura/2));
  imagem2 = imagem(Rect(altura/2, 0, altura/2, largura/2));
  imagem3 = imagem(Rect(0, largura/2, altura/2, largura/2));
  imagem4 = imagem(Rect(0, 0, altura/2, largura/2));



  imagem1.copyTo(nova_imagem(Rect(0, 0, altura/2, largura/2)));
  imagem2.copyTo(nova_imagem(Rect(altura/2, largura/2, altura/2, largura/2)));
  imagem3.copyTo(nova_imagem(Rect(altura/2, 0, altura/2, largura/2)));
  imagem4.copyTo(nova_imagem(Rect(0, largura/2, altura/2, largura/2)));

  
   imshow("Imagem", nova_imagem);
   waitKey();

  return 0;
}
--------------------

== Tarefa 3 ==

Esta tarefa corresponde ao exercício 4.1 do site da disciplina http://agostinhobritojr.github.io/tutoriais/pdi/#_preenchendo_regi%C3%B5es[Processamento Digital de Imagens] e tem como finalidade introduzir o conceito de rotulação de imagens. Rotulação é uma ferramenta muito importante não só em ciências da computação no processamento de imagens digitais, mas também em outras áreas, como engenharia e física. A grosso modo, rotulaçao é um processo usado para identificar componentes com características em comum, sendo muito usado em contagem de objetos de uma cena. 

A tarefa da seção 4, pede para identificar a situação em que mais de 255 objetos estão presentes numa determinada cena, comprometendo o processo de rotulação, tendo como exemplo o programa http://agostinhobritojr.github.io/tutoriais/pdi/#_preenchendo_regi%C3%B5es[labeling.cpp]. Aleḿ disso, pede-se que seja proposta uma solução. 

O problema surgi porque no algoritmo usado, floodfill/seedfill, as regiões ou objetos encontrados são rotulados com o tom de cinza igual ao número de objetos contados até então. Por exemplo, caso haja mais de 255 objetos, com qual tom de cinza ele será pintado, se o tom máximo só vai até esse valor? Uma solução para esse problema seria pintar as regiões com um único tom de cinza já que o resultado de quantos objetos têm na cena não vai ser alterado, que é o objetivo principal do algorítmo. No entanto, se esse processo for importante: rotular imagens com tons de cinza diferentes, seria interessante acrescentar um bloco que decrementasse o valor do contador na transição de 244 para 255, ao invés de incrementá-lo como normalmente aconteceria.


== Tarefa 4 ==

Esta tarefa é correspondente ao exercício 4.2 do site da disciplina http://agostinhobritojr.github.io/tutoriais/pdi/#_preenchendo_regi%C3%B5es[Processamento Digital de Imagens], sendo então uma extensão dos conceitos apresentados anteriormente. Pede-se o aprimoramento do http://agostinhobritojr.github.io/tutoriais/pdi/#_preenchendo_regi%C3%B5es[algorítmo de contagem]. 

O programa labeling.cpp faz o trabalho de contar e identificar os objetos furados e maciços numa cena. Primeiro, o programa busca preencher as bordas da imagem com branco e executar um floodfill com a cor preta na origem, removendo todos os objetos que estão colados nessa região. Além disso, procura-se pintar o fundo com uma cor diferente de 0, dessa forma, achando um 0, interpreta-se como um furo em algum objeto. Em seguida, busca-se os pixels com tom 255, afim de pintá-los com um nível de cinza específico para objetos maciços (objetos furados serão repintados posteriormente). Como dito anteriormente, quando o algoritmo achar um pixel de tom 0, identificará como uma bolha em um objeto e o pintará com a cor escolhida para aqueles que têm furos em sua geometria. Por fim, será execucado o floodfill na origem com a cor preta, fazendo o fundo voltar ao tom 0 e exibindo os dados processados na tela.

Obs.: o programa que segue abaixo não compilou corretamente, alguns erros foram encontrados, alguns retirados, no entanto, não conseguimos corrigir todos a tempo. O erro que aparece é mostrado abaixo e acreditamos que seja alguma biblioteca não importada ou conflito de sintaxe entre diferentes versões do OpenCV.

‘floodfill’ was not declared in this scope at line 42 col 24.

[source, c++]
-------------
#include <iostream>
#include <opencv/highgui.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#define COR_FUNDO 50
#define COR_OBJ_MACICO 80
#define COR_OBJ_FURADO 200

using namespace cv;
using namespace std;

int main (int argc, char** argv) {

    //declaração das variaveis

    Mat image;
    int height, width;
    int objetosfurado = 0;
    int objetosmacicos = 0;

    CvPoint p;
    p.y = 0;

    image = imread("imagem2.png",CV_LOAD_IMAGE_GRAYSCALE); //chamada da função que lê a imagem em grayscale

    if(!image.data){
        std::cout << "Erro: Nao foi possivel carregar a imagem.\n"; //sinal de falha na leitura da imagem
        return(-1);
    }

    //pintar as bordas de branco
    for  (int i=0; i<height; i++) {
        image.at<uchar>(0,i) = 255;
        image.at<uchar>(height-1,i) = 255;
    }

    for (int i=0; i<width; i++) {
        image.at<uchar>(i,0) = 255;
        image.at<uchar>(i,width-1) = 255;
    }

    //remove as bordas e os objetos colados nela(pintando de preto)
    floodfill(image,p,0);
    //pinta o fundo com um tom de cinza 50, para que possamos achar bolhas nos objetos comparando os pixels com o valor 0.
    floodfill (image,p,COR_FUNDO);

    //agora que todos os objetos na borda foram rejeitados, procuraremos tons 255 na imagem pixel a pixel.
    for (int i=0; i<height; i++) {
        for (int j=0; j<width; j++) {
                if (image.at<uchar>(i,j) = 255) { //objeto encontrado
                    p.x = j;
                    p.y = i;
                    floodfill(image,p,COR_OBJ_MACICO);
                    objetosmacicos++; //os objetos com furo serão subtraídos posteriormente
                }
        }
    }

    for (int i = 0; i<height; i++) {
        for (int j = 0; j<width; j++) {

            //salva as coordenadas de do ponto caso ele pertença a um objeto
            if (image.at<uchar>(i,j) == COR_OBJ_FURADO || image.at<uchar>(i,j) == COR_OBJ_MACICO) {
                p.x = j;
                p.y = i;

            }

            else if (image.at<uchar>(p.y,p.x) == COR_OBJ_MACICO) { //se o objeto estiver marcado como um objeto maciço, ele será devidamente marcado como um objeto furado(e pintado com a cor adequada).
                if (image.at<uchar>(i,j) == 0) { //como o fundo está cinza(50) um ponto preto indica um furo.
                    objetosfurado++;
                    objetosmacicos--;
                    floodfill(image,p,COR_OBJ_FURADO);
                }
            }
        }
    }

    //voltar o fundo para a cor preta e exibir a imagem/dados processados
    p.x = 0;
    p.y = 0;
    floodfill(image,p,0);
    imshow("image", image);
    imwrite("labeling.png", image);
    cout << "Contagem dos objetos com furo: " << objetosfurado << endl;
    cout << "Contagem dos objetos macicos: " << objetosmacicos << endl;
    waitKey();
    return 0;
}
-------------

== Tarefa 5 ==

Esta tarefa corresponde ao exercício 5.1 do http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[site da disciplina de Processamento Digital de Imagens], que tem como finalidade equalizar as imagens capturadas antes de exibi-las. O resultado pode ser visto e comparado com a imagem original, figura 3. Observa-se então, que a operação de equalização corresponde a aumentar o contraste da imagem. 

Para realizar a operação pedida, é válido calcular o histograma da imagem dentro de uma faixa pré estabelicida, obter o histograma acumulado, normalizá-lo e em seguida aplicar a transformação. De sorte que o OpenCV fornece uma função que faz todo esse trabalho: equalizeHist(). Ela, como o própio nome já diz, realiza a equalização do histograma, recebendo como parâmetros a componente de um vetor de matrizes e uma matriz, onde será armazenada uma determinada componente de cor. Além dessa função, foram utilizadas as funções push_back() e merge(). A primeira adiciona uma matriz como componente de um vetor de matrizes e a segunda combina várias matrizes do vetor em uma única. As demais funções podem ser visualizadas e compreendidas no http://agostinhobritojr.github.io/tutoriais/pdi/[site do professor], na sessão 5. 


Figura 3 - Equalização

image:Imagens/equalize.png[Figura 3]


[source, c++]
--------------------
#include "opencv2/opencv.hpp"
#include <iostream>

using namespace std;
using namespace cv;

int main(int, char**){

    VideoCapture cap(0); // abre camera


    if(!cap.isOpened())  // checagem
        return -1;

    namedWindow("Imagem de vídeo", 1);

    for(;;)
    {
        Mat frame;

        //Vector de matrizes para guardar as cores R, G e B
        vector<Mat> planes;
        //Pega novo frame
        cap >> frame;
        //Pega as matrizes R, G e B dos frames e guarda no vetor de matrizes, faz o inverso do merge, que será descrito abaixo.
        //Pega matriz, frame, e retira as componentes R, G e B e guarda no vetor de matrizes.
        split (frame, planes);
        //Declara três matrizes (RGB)
        Mat B,G,R;

        //Equaliza as componeste separadamente
        equalizeHist( planes[0], B );
        equalizeHist( planes[1], G );
        equalizeHist( planes[2], R );

        //Vector de matrizes
        vector<Mat> combined;
        //Adiona a matriz B equalizada ao vetor de matrizes combined
        combined.push_back(B);
        //Adiona a matriz G equalizada ao vetor de matrizes combined
        combined.push_back(G);
        //Adiona a matriz R equalizada ao vetor de matrizes combined
        combined.push_back(R);

        //Cria matriz para mostrar resultado equalizado
        Mat result;

        //combina as várias matrizes do vetor de matrizes combined (R,G e B) numa única matriz, result.
        merge(combined,result);
        //Mostra frame
        imshow("Video equalizado", result);
        imshow("Video", frame);

        if(waitKey(30) >= 0) break;
    }

      return 0;
}
--------------------

== Tarefa 6 ==

A tarefa 4 corresponde ao exercício 5.2 do http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[site do professor]. Ela tem como objetivo comparar dois histogramas de uma mesma imagem em instantes de tempo diferentes. Para realizar a comparação entre os histogramas, o OpenCV oferece a função compareHist que fornece quatro métricas diferentes que podem ser utilizadas para comparação: CV_COMP_CORREL,  CV_COMP_CHISQR, method=CV_COMP_INTERSECT e CV_COMP_BHATTACHARYYA. As explicações de cada uma se encontra no http://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.html[portal de documentação do OpenCV]. Para esta prática a métrica  CV_COMP_CHISQR, foi escolhida sem nenhum motivo em especial. Ela obtém o somatório da divisão entre o quadrado da diferença do primeiro com o segundo, dividido pelo primeiro. 

O progama abaixo faz o cálculo do primeiro histograma em um dado instante, normaliza-o e o exibe dentro da imagem capturada. Depois calcula o segundo histograma da mesma imagem e o normaliza. Logo em seguida, a comparação é efetuada, passando-se os dois histogramas e o método da comparação. Quando o valor da comparação for menor que 200, aparece a mensagem "ULTRAPASSOU O LIMITE ESTABELECIDO". 

Para maiores detalhes das outras funções encontradas no código, recomenda-se o http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[site da disciplina].



[source, c++]
--------------------
#include <iostream>
#include <stdlib.h>
#include <opencv2/opencv.hpp>
#include <bits/stdc++.h>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;

  VideoCapture cap;
  vector<Mat> planes;
  Mat histR, histR_1;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  cap.open(0);

  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }


  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  //Não precisa de mais um cálculo

  while(1){
    cap >> image;
    split (image, planes);

    //Calculando o histograma no instante
    calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);
    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());

    histImgR.setTo(Scalar(0));


    for(int i=0; i<nbins; i++){
      line(histImgR, Point(i, histh),
           Point(i, cvRound(histR.at<float>(i))),
           Scalar(0, 0, 255), 1, 8, 0);

    }
    histImgR.copyTo(image(Rect(0, 0,nbins, histh)));
    

    calcHist(&planes[0], 1, 0, Mat(), histR_1, 1,
              &nbins, &histrange,
              uniform, acummulate);

    normalize(histR_1, histR_1, 0, histImgR.rows, NORM_MINMAX, -1, Mat());

    //usando o segundo método de comparação
    double comp = compareHist(histR, histR_1, 2);
    if(comp > 600){
      std::cout << "\a\a\a" << std::endl;
      std::cout << "ULTRAPASSOU O LIMITE ESTABELECIDO" << std::endl;

    }

    imshow("image", image);

     if(waitKey(30) >= 0) break;
   }


  return 0;
}
--------------------

== Tarefa 7 ==
A tarefa 5 Corresponde ao exercício 6.2 em, http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[github do professor]. Essa tarefa tem por finalidade apresentar 5 tipos de filtros já implementados no programa base do link mostrado. A saber, filtro da média, detector de bordas verticais e horizontais, gaussiano e laplaciano. Além de apresentá-los, pede-se para gerar um efeito do filtro do laplaciano do gaussiano.

O resultado pode ser visualizado na imagem a seguir. Comparando-o com o laplaciano e o gaussiano, pode-se chegar a conclusão que o filtro laplaciano do gaussiano tem as característacas dos dois, ou seja, uma pequena atenuação proviniente do gaussiano e um acentuado realce em regiões de descontinuidade do laplaciano. 

Em relação a programação, ao código base foi acrescentado um "case" onde o laplaciano do gaussiano é realizado. Para um maior entendimento, sugere que se vá ao endereço http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_3[eletrônico da disciplina]. Lá se encontra uma descrição melhor de todo o código. 


Figura 3 - Lapaciano do Gaussiano

image:Imagens/LoG.png[Laplaciano do Gaussiano] 


[source, c++]
--------------------
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
    "m - media\n"
    "g - gauss\n"
    "v - vertical\n"
	"h - horizontal\n"
    "l - laplaciano\n"
      "t - laplaciano-gaussiano\n"
	"esc - sair\n";
}

int main(int argvc, char** argv){
  VideoCapture video;
  //Maskaras
  float media[] = {1,1,1,
				   1,1,1,
				   1,1,1};
  float gauss[] = {1,2,1,
				   2,4,2,
				   1,2,1};
  float horizontal[]={-1,0,1,
					  -2,0,2,
					  -1,0,1};
  float vertical[]={-1,-2,-1,
					0,0,0,
					1,2,1};
  float laplacian[]={0,-1,0,
					 -1,4,-1,
					 0,-1,0};
  //Declaração das variáveis do tipo Mat
  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
  // double width, height, min, max;
  int absolut;
  char key;

  video.open(0);
  if(!video.isOpened())
    return -1;


  namedWindow("filtroespacial",1);
  //Inicialmente a máscara vai receber a máscara da média
  mask = Mat(3, 3, CV_32F, media);
  //Retirei a ganho que se tinha pra media
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1); //Pra dar o ganho de 1/9 na máscara da mádia
  swap(mask, mask1);
  absolut=1; // calcs abs of the image

  menu();
  for(;;){
    video >> cap;
    //Converte cap em cinza e manda pra frame
    cvtColor(cap, frame, COLOR_BGR2GRAY);
    flip(frame, frame, 1);
    //Mostra imagens originais
    imshow("original", frame);
    //Frame é convertido pra ponto flutuante e jogado em frame32f
    //Filtra e joga em frameFiltered. Usa mask como maskara. A média inicialmente
    frame.convertTo(frame32f, CV_32F);
    filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);

    if(absolut){
      frameFiltered=abs(frameFiltered);
    }
    //Converte frameFiltered pra poder exibir
    frameFiltered.convertTo(result, CV_8U);
    imshow("filtroespacial", result);

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
	  menu();
      absolut=!absolut;
      break;
    case 'm':
	  menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'g':
	  menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'h':
	  menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      break;
    case 'v':
	  menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      break;
    case 'l':
	  menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);

      break;
    case 't':
    menu();
        // mask recebe os coeficientes da matriz do laplaciano
        // Não precisa converter pra cv_32f, pois a imagem (frame) já entra convertida
        // depois disso se usa a função filter2D() para realizar o filtro do laplaciano. O código segue ainda dentro do case, onde agora
        // mask vai receber a máscara pro gaussiano, recebe um ganho através da função scaleAdd(), sai do break e volta pro começo do loop infinito
        // onde deve ser filtrada por filter2D()
        mask = Mat(3, 3, CV_32F, laplacian);
        filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);



        mask = Mat(3, 3, CV_32F, gauss);
        scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
        swap(mask, mask1);
        
        std::cout << "Laplaciano-gaussiano" << std::endl;
        break;

    default:
      break;
    }
  }
  return 0;
}

--------------------


= Tarefas referentes à segunda unidade da disciplina de Processamento Digital de Imagens =
= Tarefa I =

Começamos essa tarefa por introduzir, resumidamente, o filtro de Canny ou o detector de bordas de Canny. Trata-se de um algoritmo que utiliza os conceitos de convolução digital e de cálculo do gradiente. A princípio, Canny buscava um algoritmo ótimo que, como provado, conseguiu, porém conseguiu para os três critérios que ele estabeleceu. O primeiro critério estabelecido por Canny foi o de que as bordas encontradas devem ser o mais próximas possíveis das verdadeiras, ou seja, ter baixa taxa de erro. O segundo foi que a distância entre um ponto marcado como uma borda e o centro da borda verdadeira deve ser a menor possível. E o último foi que o número de máximos locais retornados por uma borda deve ser mínimo.

O filtro de Canny consiste em suavizar a imagem por um filtro Gaussiano, obter a magnitude do gradiente, bem como os ângulos da imagem, aplicar a supressão de não máximos, que tem por finalidade afinar as cristas da imagem e a limiarização por histeresse que se utiliza de dois limiares. Esta tarefa une os conceitos utilizados pelo detector de bordas de Canny e a técnica de Pontilhismo, que é uma técnica de pintura em que pequenas manchas, círculos ou pontos são introduzidos na imagem. Tendo como base os dois códigos disponibilizados no site do professor, http://agostinhobritojr.github.io/tutoriais/pdi/#_detec%C3%A7%C3%A3o_de_bordas_com_o_algoritmo_de_canny[canny.cpp] e  http://agostinhobritojr.github.io/tutoriais/pdi/#_canny_e_a_arte_com_pontilhismo[pontilhismo.cpp], o código foi implementado mesclando as funcionalidades de cada um deles. Foi criada uma função para a implementação do pontilhismo, seguindo a mesma ideia do código referência, onde a função circle, disponibilizada pelo OpenCV, traça círculos de raios especificados pelo usuário. Vale lembrar que antes de tudo, o filtro de Canny é aplicado utilizando a função que o próprio OpenCV fornece, Canny, que recebe a imagem de interesse, a matriz onde o resultado do filtro será escrito e os limiares. Por último, vale destacar que pelo filtro retornar uma imagem com bordas, em um fundo escuro, fez­se necessário que cada pixel fosse diminuído por 255, fazendo com que a imagem ficasse clara. A imagem original e o resultado seguem logo abaixo, assim como o código. Vale lembrar que para maiores informações das funções utilizadas aqui, basta dar uma olhada no site do professor

[http://agostinhobritojr.github.io/tutoriais/pdi/]

= Conclusão =

A biblioteca OpenCV é estremamente útil para o Processamento Digital de Imagens, através dela pode-se evidenciar na prática o que foi visto em aulas teóricas ministradas no curso de Processamento Digital de Imagens, como por exemplo, filtros de imagens digitais, tarefas relacionadas aos histogramas, manipulação de pixels, processo de contagem e rotulação de imagnes, entre outros. A docmunentação do OpenCV é bastante rica e didática, apresentando diversos exemplos, proporcionado com isso uma fácil manipulação de imagens. 


= Bibliografia =
[bibliography]
- http://docs.opencv.org/ - Principal portal de documentação OpenCV.
- http://agostinhobritojr.github.io/tutoriais/pdi/. - Site de referência para as tarefas em OpenCV.
